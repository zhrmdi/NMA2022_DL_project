# NMA2022-project
Deep learning project for NMA 2022: **Modelling how the brain deals with noisy input.** <br/>
Based on NMA's [Vision with Lost Glasses](https://deeplearning.neuromatch.io/projects/Neuroscience/blurry_vision.html) project. More details please go here (https://docs.google.com/document/d/15Rvs5GjQjHbFSAzl1D1fUynAPN0RQZGP6V5gtR7EkpE/edit#heading=h.vl6rn3oq6crb)

## Objective

<p align="justify"> Imagine you lost your spectacle and the world around you is completely blurred out. As you stumble around, you see a small animal walk towards you. Can you figure out what it is? Probably yes, right? In this situation, or in foggy/night-time conditions, visual input is of poor quality; images are blurred and have low contrast and yet our brains manage to recognize it. Is it possible to model the process? Does previous experience help? </p>
